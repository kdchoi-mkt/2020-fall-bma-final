# Query String 데이터 전처리 개요
1. 기사 정보 및 백과사전 정보를 스크래핑
2. Word 2 Vec를 이용해서 단어를 vectorization시킴
3. 단어 vector를 통해 cluster model을 구성
4. 유저의 search keyword 데이터를 정제시키고, 간단한 기초 변수를 만듦
5. 각 search keyword를 Word 2 Vec을 이용해 vector화 시키고, label함
6. 각 유저별, label 별 기초 변수 통계 데이터를 구성함

# Query String에서 논의한 점들
## QRY_STR에서 어떻게 단어를 선택할 것인가?
QRY_STR의 구성은 다음 중 하나임
+ something
+ something&~~~~~~
+ anything&~~~~&query=something

다음 세 가지 모두에서 something이 가장 의미있는, 실제로 유저가 검색했음직한 단어라고 간주함

## 단어 데이터를 어떻게 의미있게 만들 것인가?
### 일괄적으로 one-hot encoding을 하면 생기는 현상
+ 새로운 단어에 대해서는 projection이 불가함
+ "메이플 스토리"와 "게임" 등과 같이 유사한 단어임에도 불구하고 서로 다른 단어로 인식됨
### 해결방안: Word 2 Vec
+ 문장 데이터를 통해서 단어를 n차원 벡터로 embed 시키는 학습 방법
+ 이를 위해서는 외부의 데이터를 이용하여 학습해야함
+ 따라서, 가장 오타가 없을 것으로 생각되는 백과사전과, 그 시대 당시의 흐름을 나타내줄 수 있는 기사 데이터를 크롤링하여 단어를 학습시킴
### 문제점: 새로운 단어, 문장에 대해서 계산할 수 없다
+ 서치 데이터가 문장인 경우, 단어로 쪼개서 각각을 벡터화 시킨 후 더해서 문장 벡터를 만듬
+ 서치 데이터와 단어가 매치되지 않는 경우, 결측치 데이터로 간주하고 `0벡터`로 초기화
+ 만약 최종 문장 벡터가 0벡터인 경우, 따로 레이블링을 -1로 하여 아무 레이블에도 속하지 못하게 분류
### 단어 벡터 vs 단어 분류
+ 단어 벡터 자체는 아무 의미가 없음
+ 일반적으로 단어를 벡터화시켜 단어간 거리를 계산하여 클러스터링 하는 방법을 사용
+ 이 때 Elbow Method를 사용하여 군집 개수를 지정
    + Elbow Method는 클러스터가 증가함에 따라 클러스터의 '관성'이 변하는 그래프를 그렸을 때, 가장 경사가 완만해지는 지점을 클러스터 개수로 정하는 방법론
    + 이번 분석에서는 3 ~ 100까지의 클러스터에 대한 관성을 그렸으며, 최종으로 클러스터 개수가 40일 때 경사가 완만해진다고 간주되어 클러스터 개수를 40으로 지정
## 서치 분류 후 작업
1. 각 사람 별, 레이블 별마다 다음을 측정
    + 검색 횟수 총 합
    + 서로 다른 검색 수
    + 단어 길이 평균
    + 단어 개수 평균
2. 그 후, pivot table을 이용하여 사람만 index가 오고 나머지 레이블 별 통계량이 column으로 가게 데이터 셋을 구성